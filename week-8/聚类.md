###聚类
聚类算法是非监督学习算法，将并没有明确的标签数据中，输入算法中，找到这些数据中

的内在联系，一个能够找到圈出这些点集，被称为聚类算法

![image](https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week8/image/聚类1.PNG?raw=true)


### K-MEANS
    - 算法接受参数K，然后将事先输入的n个数据
    对象划分为k个聚类以便使得所获得的聚类满足：
    同一聚类中的对象相似度较高，
    而不同聚类中的对象相似度较小
    
    - 算法思想：以空间中k哥点为中心进行聚类，
    对最靠近他们的对象归类。
    通过迭代的方法，逐次更新各聚类中心得值，
    直至得到最好的聚类结果
    
具体步骤：

    1. 先从没有标签的元素集合A中随机取K个元素，作为K个子集各自的重心
    2. 分别计算剩下的元素到k个子集重心的距离（这里的距离也可以使用欧式距离）,
    根据距离将这些元素分别划归到最近的子集
    3. 根据聚类结果，重新计算重心（重心的计算方法是计算子集中所以元素各个维度的算术平均值）
    4.将集合A中全部元素按照新的重心然后再重新聚类
    5. 重复第4步， 直到聚类结果不在发生变化
    

如下有四个点，假设取（1,1）（2,1）为两个分类的中心点
![image](https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week-8/image/聚类2.PNG?raw=true)

然后计算所有的点到中心的距离：

![image](https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week-8/image/聚类3.PNG?raw=true)

> 第一行是所有点到第一类点的距离，第二行是所有点到第二类点的距离

然后根据距离的大小将四个点进行分类

![image](https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week-8/image/聚类4.PNG?raw=true)

> 第一行代表第一个类别，第二行代表第二个类别


然后重新计算重心：

第二个类别C2：

![image](https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week-8/image/聚类5.PNG?raw=true)

然后重复以上步骤：
![image](https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week-8/image/聚类6.PNG?raw=true)

直到聚类不发生变化

### Mini Batch K-Means
Mini Batch K-means算法是k-Means算法的变种，采用小批量的数据子集减少计算时间，这里所谓的小批量是指每次训练算法时所随机抽取的数据子集，

采用这些随机产生的子集进行训练算法，大大减少了计算时间，结果一般只略差于标准算法。

该算法的迭代步骤有两步：

1. 从数据集中随机抽取一些数据形成小批量，把他们分配给最近的质心
2. 更新质心， 与k均值算法相比，数据的更新是在每一个的样本集上。mini Batch K-Means 比K-means有更快的，收敛速度，
但同时也降低了聚类的效果，但是在实际项目中却表现的不明显。


### K-MEANS算法分析
k-means算法在有些情况下是会出现问题的：

1. 对k个初始质心得选择比较敏感，容易陷入局部最小值。例如，我们上面的算法运行的时候，有可能会得到不同的结果，如下面这两种情况。K-means也是收敛了，只是收敛了局部最小值：

![image](https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week-8/image/kmeans1.PNG?raw=true)

2. k的值选择是用户决定的，不同的k得到的结果会有挺大的不同，如图所示，左边是k = 3 的结果，蓝色的簇太稀疏了，蓝色的簇应该可以在划分成两个簇。右边是k=5的结果，红色和蓝色的簇应该合并成为一个簇

![image](https://github.com/jccjd/Coursera-Machine-Learning/blob/master/week-8/image/kmeans2.PNG?raw=true)

3. 存在局限性，如下这种非球状的数据结构分布不适用：






